
<!--DOCTYPE-->
<!DOCTYPE html>
<html>
<head>
    <title>MVAST</title>
    <link rel="SHORTCUT ICON" href="favicon.ico"/>
    <link href='css/test.css' rel='stylesheet' type='text/css'>
</head>

<body>

<div class="pageTitle">
    Multi-view Arbitrary Style Transfer
    <br>
    <br>
    <span class = "Authors">
        <p style="margin-bottom: 0px; padding-bottom: 0px">
            <a href="https://scholar.google.com/citations?user=u-9bdkwAAAAJ&hl=en" target="_blank">Taekyung Kim</a><sup>1,3*</sup> &nbsp; &nbsp;
            <a href="https://scholar.google.com/citations?user=ABH_2lcAAAAJ&hl=en" target="_blank">Changick Kim</a><sup>3</sup> &nbsp; &nbsp;
        </p>
        <p>
            Korea Advanced Institute of Science and Technology &nbsp; &nbsp;
        </p>
        <!--<a href="" target="_blank"><i>.</i></a>(Oral)-->
  </span>
</div>
<br>
<div class = "material">
    <!--<a href="#" target="_blank">[ArXiv Preprint]</a>-->
    <!--<a href="#" target="_blank">[Code (Github)]</a>-->
    <!--<a href="#" target="_blank">[BibTex]</a>-->
    <!--<a href="#" target="_blank">[Material]</a>-->
    <!--a href="#" target="_blank">[Video]</a>-->
    <br>
</div>



<div class = "abstractTitle">
    Abstract
</div>

<p class = "abstractText">
    In this paper, we introduce pioneering algorithms for multi-view arbitrary style transfer. Multi-view arbitrary style transfer is an advanced study of the conventional monocular arbitrary style transfer, which aims to preserve the consistent style on the common region across the given arbitrary number of views. We intend to address the multi-view inconsistency problem by minimizing the difference in the color and feature values of the corresponding regions. However, the conventional feature extractors generally produce a feature vector of a point from its rectangular local patch, and such local patches are misaligned across the views in a multi-view environment due to various camera poses.  Thus, even if we assimilate the feature vectors of the corresponding pixels, since the spatial distribution of the surrounding feature vectors within their local patches are different and decoding such misaligned patches induces misaligned brushstrokes and geometric patterns, these feature vectors can be decoded to distinctive style texture. Based on the observation, we intend to interpret this challenging problem in terms of the photometric inconsistency and the stroke inconsistency. We propose a photometric consistency loss, which directly enforces the geometrically consistent style texture across the view, and a stroke consistency loss, which matches the characteristics and directions of the brushstrokes by aligning the local patches of the corresponding pixels before minimizing feature deviation. Then, We construct an optimization-based multi-view arbitrary style transfer framework (MVAST-O) with photometric and stroke consistency losses and extend it to a feed-forward framework (MVAST-FF) to overcome the chronic computational inefficiency issue of optimization-based algorithms. We validate our methods on the DTU dataset, a large-scale multi-view stereo dataset, and confirmed the superiority on preserving appearance consistency throughout the stylized multi-view images.
</p>

<img class = "bannerImage" src="images/intro.png", width="800"><br>
<table width="800" align="center"><tr><td><p class = "figureTitleText">
    Figure 1. Visualization of the inconsistent stylized texture in spatially corresponding areas. (a) Given
3-view images and a style image, we compared the stylization results of conventional monocular
style transfer method (first row) and our method (second row).

</p></td></tr></table>


<img class = "bannerImage" src="images/qual.png", width="800"><br>
<table width="800" align="center"><tr><td><p class = "figureTitleText">
    Figure 2. Qualitative comparisons with arbitrary style transfer baselines and our methods.
</p></td></tr></table>




</p></td></tr></table>
</body>
</html>
